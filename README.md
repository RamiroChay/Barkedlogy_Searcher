# ğŸš€ BARKEDLOGY: Space Biology Knowledge Engine

<p align="center">
  <img src="assets/logo_largo.png" alt="Logo Barkedlogy" width="150">
</p>

**Barkedlogy** es una plataforma web interactiva y un motor de conocimiento diseÃ±ado para democratizar el acceso a la investigaciÃ³n cientÃ­fica sobre biologÃ­a espacial de la NASA.

A diferencia de un buscador tradicional que solo busca palabras clave, Barkedlogy utiliza algoritmos de **Machine Learning (Reglas de AsociaciÃ³n)** para "entender" el contexto, sugiriendo tÃ©rminos relacionados cientÃ­ficamente (por ejemplo, relacionando "Microgravedad" con "PÃ©rdida Ã“sea" aunque el usuario no lo escriba explÃ­citamente).

<p align="center">
  <img src="assets/docs/prueba2.png" alt="Vista Previa Home" width="650">
</p>

---

## ğŸ“‹ Tabla de Contenidos

1. [DescripciÃ³n General y PropÃ³sito](#-descripciÃ³n-general-y-propÃ³sito)
2. [CaracterÃ­sticas Principales](#-caracterÃ­sticas-principales)
3. [Ciencia de Datos y LÃ³gica del Motor](#-ciencia-de-datos-y-lÃ³gica-del-motor)
4. [Arquitectura del Sistema](#-arquitectura-del-sistema)
5. [Detalles de ImplementaciÃ³n Frontend](#-detalles-de-implementaciÃ³n-frontend)
6. [Estructura del Proyecto](#-estructura-del-proyecto)
7. [InstalaciÃ³n y Uso Local](#-instalaciÃ³n-y-uso-local)
8. [Despliegue (Deployment)](#-despliegue-deployment)
9. [API Endpoints](#-api-endpoints-principales)
10. [TecnologÃ­as Utilizadas](#-tecnologÃ­as-utilizadas)

---

## ğŸŒ DescripciÃ³n General y PropÃ³sito

El volumen de publicaciones cientÃ­ficas de la NASA es inmenso y a menudo difÃ­cil de navegar para estudiantes o investigadores externos. El objetivo de este proyecto fue crear una interfaz amigable que no solo liste documentos, sino que **guÃ­e al usuario** a travÃ©s de temas conectados.

El sistema procesa un dataset de publicaciones de biologÃ­a espacial, las agrupa en categorÃ­as lÃ³gicas (Clusters) y descubre relaciones ocultas entre conceptos cientÃ­ficos para mejorar la experiencia de bÃºsqueda.

---

## âœ¨ CaracterÃ­sticas Principales

### ğŸ” Buscador SemÃ¡ntico Inteligente
* **Autocompletado Contextual:** Al escribir, el sistema no solo sugiere frases que completan la palabra, sino conceptos cientÃ­ficos relacionados basados en el cÃ¡lculo de **Lift** y **Confianza** de las reglas de asociaciÃ³n.
* **ExpansiÃ³n de Consulta:** Si un usuario busca un tÃ©rmino, el backend busca automÃ¡ticamente sinÃ³nimos y tÃ©rminos fuertemente asociados en la base de datos.

### ğŸŒŒ ExploraciÃ³n Visual por Clusters
* **CategorizaciÃ³n AutomÃ¡tica:** Los artÃ­culos estÃ¡n organizados en 19 clusters temÃ¡ticos definidos por algoritmos de NLP (Procesamiento de Lenguaje Natural).
* **Identidad Visual:** Cada categorÃ­a (ej. "RadiaciÃ³n", "ExpresiÃ³n GÃ©nica") posee una identidad visual Ãºnica con imÃ¡genes generadas que facilitan la identificaciÃ³n rÃ¡pida.

<p align="center">
  <img src="assets/docs/prueba3.png" alt="Vista de Clusters" width="650">
</p>

### ğŸ“± DiseÃ±o Responsivo (Mobile-First)
* **Adaptabilidad Total:** La interfaz se transforma fluidamente desde pantallas de escritorio grandes hasta dispositivos mÃ³viles pequeÃ±os.
* **MenÃº Tipo "Persiana":** En mÃ³viles, la navegaciÃ³n lateral se convierte en un menÃº superior desplegable para maximizar el espacio de lectura.
* **TipografÃ­a Legible:** Ajuste dinÃ¡mico de tamaÃ±os de fuente y mÃ¡rgenes para evitar la fatiga visual en pantallas pequeÃ±as.

<p align="center">
  <img src="assets/docs/prueba6.jpg" alt="Vista MÃ³vil" width="350">
</p>

### âš¡ Experiencia de Usuario (UX) Optimizada
* **Carga Progresiva (Lazy Loading):** ImplementaciÃ³n de paginaciÃ³n dinÃ¡mica ("Cargar mÃ¡s") para manejar miles de artÃ­culos sin congelar el navegador.
* **Persistencia de Estado:** Uso de `localStorage` para recordar la bÃºsqueda y la posiciÃ³n del usuario al navegar entre el listado y los detalles del artÃ­culo.

---

## ğŸ§  Ciencia de Datos y LÃ³gica del Motor

El "cerebro" del proyecto reside en cÃ³mo se procesaron los datos antes de llegar a la web:

1. **Limpieza de Datos:** Procesamiento de `final_dataset.csv` para normalizar resÃºmenes (abstracts) y tÃ­tulos.
2. **Clustering (Agrupamiento):** Se utilizaron algoritmos no supervisados para agrupar los artÃ­culos en **19 temas principales** (Clusters), asignando a cada uno un ID y un nombre descriptivo (ej. Cluster 105: "Mecanismos de BiologÃ­a Celular").
3. **Reglas de AsociaciÃ³n (Apriori):**
   * Se generaron reglas del tipo: *Si aparece "EstrÃ©s Oxidativo", entonces es probable que aparezca "Mitocondria"*.
   * Estas reglas se almacenan en `apriori_rules.json` y son consumidas por la API para potenciar las sugerencias de bÃºsqueda.

---

## ğŸ— Arquitectura del Sistema

El proyecto sigue una arquitectura **Cliente-Servidor desacoplada**, lo que permite escalar cada parte de forma independiente.

### 1. Backend (API REST)
* **TecnologÃ­a:** Python + FastAPI.
* **Responsabilidad:** Cargar los modelos de ML en memoria, filtrar el dataset de pandas en tiempo real y servir las respuestas en formato JSON.
* **Despliegue:** La API se desplegÃ³ y estÃ¡ corriendo en la nube a travÃ©s de **Render**.

### 2. Frontend (SPA - Single Page Application feel)
* **TecnologÃ­a:** HTML5, CSS3, JavaScript (Vanilla).
* **FilosofÃ­a:** "Sin Frameworks". Se optÃ³ por JavaScript puro para garantizar el mÃ¡ximo rendimiento y control total sobre el DOM.
* **Despliegue:** La pÃ¡gina web se levantÃ³ y estÃ¡ hospedada estÃ¡ticamente en **GitHub Pages**.

---

## ğŸ¨ Detalles de ImplementaciÃ³n Frontend

* **AnimaciÃ³n de Olas:** Se implementÃ³ una animaciÃ³n CSS pura con `SVG` y `keyframes` para crear un efecto de "ocÃ©ano de conocimiento" en el encabezado, optimizada para no consumir CPU en mÃ³viles.
* **Sistema de Grid DinÃ¡mico:** Las tarjetas de artÃ­culos utilizan `display: grid` con `minmax` para auto-organizarse segÃºn el ancho de la pantalla disponible.
* **Manejo de Errores en ImÃ¡genes:** Script de fallback que detecta si una imagen de cluster no existe y la reemplaza automÃ¡ticamente por un placeholder para no romper la estÃ©tica.

---

## ğŸ“‚ Estructura del Proyecto

```bash
/proyecto-raiz
â”‚
â”œâ”€â”€ /assets                 # Recursos estÃ¡ticos
â”‚   â”œâ”€â”€ /clusters           # ImÃ¡genes especÃ­ficas por ID de cluster (100.jpg...)
â”‚   â”œâ”€â”€ /docs               # ImÃ¡genes para documentaciÃ³n
â”‚   â”œâ”€â”€ logo_barquito.png   # Logotipo principal
â”‚   â””â”€â”€ ...
â”‚
â”œâ”€â”€ index.html              # Landing Page con buscador principal
â”œâ”€â”€ search_page.html        # Interfaz de resultados con filtros y grid
â”œâ”€â”€ article.html            # Vista de lectura inmersiva del artÃ­culo
â”‚
â”œâ”€â”€ styles.css              # Hoja de estilos maestra (Variables, Layout, Responsive)
â”œâ”€â”€ script.js               # Controlador lÃ³gico (Fetch API, Renderizado DOM, Eventos)
â”‚
â””â”€â”€ /backend                # LÃ³gica del Servidor
    â”œâ”€â”€ /src
    â”‚   â”œâ”€â”€ api.py          # Punto de entrada de FastAPI
    â”‚   â”œâ”€â”€ requirements.txt # Lista de dependencias (pandas, scikit-learn...)
    â”‚   â”œâ”€â”€ models/         # Archivos JSON con reglas de asociaciÃ³n y clusters
    â”‚   â””â”€â”€ data/           # Datasets CSV procesados
```

ğŸ’» InstalaciÃ³n y Uso Local
PrerrequisitosPython 3.9 o superior.Git instalado.
1. * **Clonar el repositorioBashgit** * `clone` [https://github.com/ramirochay/barkedlogy.git](https://github.com/ramirochay/barkedlogy.git)
`cd barkedlogy`
2. Configurar el Backend (Python)Navega a la carpeta del cÃ³digo fuente del backend:Bashcd backend/src

# (Recomendado) Crear entorno virtual
python -m venv venv
# Activar: source venv/bin/activate (Mac/Linux) o venv\Scripts\activate (Windows)

# Instalar librerÃ­as necesarias
pip install -r requirements.txt

# Iniciar el servidor localmente
uvicorn api:app --reload
El servidor estarÃ¡ escuchando en http://127.0.0.1:80003. Configurar el FrontendAbre el archivo script.js en la raÃ­z del proyecto.Busca la constante API_URL en las primeras lÃ­neas.Cambia la URL de producciÃ³n por la local:JavaScriptconst API_URL = "[http://127.0.0.1:8000](http://127.0.0.1:8000)";
Abre index.html en tu navegador web.

## ğŸš€ Despliegue (Deployment)

El proyecto estÃ¡ configurado para un despliegue continuo (CI/CD) utilizando servicios en la nube gratuitos para garantizar la accesibilidad pÃºblica.

### Backend (API)
* Se desplegÃ³ utilizando **Render** como plataforma PaaS.
* El servicio detecta automÃ¡ticamente los cambios en la rama principal (`main`) y reconstruye el entorno Python instalando las dependencias desde `requirements.txt`.
* **ConfiguraciÃ³n:** Se forzÃ³ el uso de `PYTHON_VERSION = 3.9.18` para asegurar compatibilidad total con librerÃ­as cientÃ­ficas como Pandas y Scikit-learn.

### Frontend (Web)
* La pÃ¡gina se levantÃ³ utilizando **GitHub Pages**, lo que permite acceder a la aplicaciÃ³n desde cualquier dispositivo sin necesidad de instalaciÃ³n.
* **URL PÃºblica:** [https://ramirochay.github.io/Barkedlogy_Searcher/index.html](https://ramirochay.github.io/Barkedlogy_Searcher/index.html)
* Se conecta de forma segura (HTTPS) a la API alojada en Render para obtener los datos en tiempo real.

---

## ğŸ“¡ API Endpoints Principales

| MÃ©todo | Endpoint | DescripciÃ³n |
| :--- | :--- | :--- |
| `GET` | `/clusters` | Devuelve la lista de las 19 categorÃ­as temÃ¡ticas y su conteo de artÃ­culos. |
| `GET` | `/articles` | Endpoint principal de bÃºsqueda. Soporta filtros por texto, ID de cluster y paginaciÃ³n (`skip`/`limit`). |
| `GET` | `/associations` | Devuelve reglas de asociaciÃ³n (sugerencias) basadas en un tÃ©rmino de entrada y un umbral de confianza. |

---

## ğŸ›  TecnologÃ­as Utilizadas

* **Lenguajes:** Python 3.9, JavaScript (ES6+), HTML5, CSS3.
* **Frameworks Backend:** FastAPI.
* **Servidor:** Uvicorn.
* **Data Science:** Pandas, Scikit-learn, Mlxtend.
* **Control de Versiones:** Git & GitHub.
* **Infraestructura:** Render (Backend) y GitHub Pages (Frontend).